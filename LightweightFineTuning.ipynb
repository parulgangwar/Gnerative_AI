{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f35354cd",
   "metadata": {},
   "source": [
    "# Lightweight Fine-Tuning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "560fb3ff",
   "metadata": {},
   "source": [
    "TODO: In this cell, describe your choices for each of the following\n",
    "\n",
    "* PEFT technique: \n",
    "* Model: \n",
    "* Evaluation approach: \n",
    "* Fine-tuning dataset: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8a4d7e",
   "metadata": {},
   "source": [
    "As a part of Generative Artifcial Intelligence Nanodegree program by Udacity, this is my first project on \"Apply Lightweight Fine-Tuning to a Foundation Model\" Lightweight fine-tuning is one of the most important techniques for adapting foundation models, because it allows is to modify foundation models for \n",
    "our needs without needing substantial computational resources.\n",
    "\n",
    "Parameter-efficient fine-tuning is a technique to use pre-trained machine learning models with minimal additional data or computational resources. Basically in this technique, we use specific parameters rather than retraining the entire model. This approach, often used in transfer learning, accelerates convergence and enhances generalization, particularly in NLP, computer vision, and related fields.\n",
    "\n",
    "In this project, I've applied parameter-efficient fine-tuning using the Hugging Face peft library. In order to do, I've followed following steps.\n",
    "\n",
    "Step 1: Load a Pre-trained Model and Evaluate Its Performance\n",
    "I have used thee \"distilbert-base-uncased\" model from Hugging Face peft library. I  have used the subset of Amazon Polarity dataset. As entire dataset was quite heavy.\n",
    "In this step, I have prepared the dataset and have evaluated the pre-trained model's performance on the validation dataset.\n",
    "\n",
    "Step 2: Perform Parameter-Efficient Fine-Tuning Using the Pre-trained Model\n",
    "In this step, I've defined training arguments for fine-tuning and have also Fine-tuned the pre-trained model on the training subset.\n",
    "I've also saved the fine-tuned model.\n",
    "\n",
    "Step 3: Perform Inference Using the Fine-Tuned Model and Compare Its Performance to the Original Model\n",
    "In this step, I've loaded the fine-tuned model and have evaluated the fine-tuned model's performance on the validation dataset.\n",
    "I've also compared the trainer evaluation results with the final fine-tuned evaluation results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8d76bb",
   "metadata": {},
   "source": [
    "## Loading and Evaluating a Foundation Model\n",
    "\n",
    "TODO: In the cells below, load your chosen pre-trained Hugging Face model and evaluate its performance prior to fine-tuning. This step includes loading an appropriate tokenizer and dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f5c8100",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install scikit-learn torch transformers datasets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c197926b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/tmp/ipykernel_553/4284527552.py:21: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\", trust_remote_code=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results on Trainer: {'eval_loss': 0.6916698217391968, 'eval_accuracy': 0.5125, 'eval_runtime': 2.1527, 'eval_samples_per_second': 185.814, 'eval_steps_per_second': 6.504}\n"
     ]
    }
   ],
   "source": [
    "# This step is to import libaries\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
    "from datasets import load_dataset, load_metric\n",
    "\n",
    "# This step is to create tokenizer from pre-trained model \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)\n",
    "\n",
    "# This step is to load Amazon Polarity dataset and to create a small subset for training and validation\n",
    "ds_amazon_polarity = load_dataset(\"amazon_polarity\")\n",
    "train_dataset = ds_amazon_polarity[\"train\"].shuffle(seed=42).select(range(2000))\n",
    "val_dataset = ds_amazon_polarity[\"test\"].shuffle(seed=42).select(range(400))\n",
    "\n",
    "# This step is to Tokenize datasets\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"content\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "tokenized_val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "metric = load_metric(\"accuracy\", trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(eval_op):\n",
    "    predictions = eval_op.predictions.argmax(-1)\n",
    "    return metric.compute(predictions=predictions, references=eval_op.label_ids)\n",
    "\n",
    "# This step is to set training arguments and to evaluate Trainer\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    per_device_eval_batch_size=30,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Evaluate pre-trained model performance\n",
    "Evaluation_result = trainer.evaluate()\n",
    "print(f\"Evaluation results on Trainer: {Evaluation_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d52a229",
   "metadata": {},
   "source": [
    "## Performing Parameter-Efficient Fine-Tuning\n",
    "\n",
    "TODO: In the cells below, create a PEFT model from your loaded model, run a training loop, and save the PEFT model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894046c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='67' max='67' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [67/67 00:21, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.689200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.690100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.689700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>0.685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.678000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.661900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# These steps are for training arguments for fine-tuning\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=1, \n",
    "    per_device_train_batch_size=30,\n",
    "    per_device_eval_batch_size=30,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    save_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_train_dataset,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "# Fine-tune the model\n",
    "trainer.train()\n",
    "trainer.save_model(\"./peft_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615b12c6",
   "metadata": {},
   "source": [
    "## Performing Inference with a PEFT Model\n",
    "\n",
    "TODO: In the cells below, load the saved PEFT model weights and evaluate the performance of the trained PEFT model. Be sure to compare the results to the results from prior to fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "866ab28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14/14 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final evaluation result: {'eval_loss': 0.6143025755882263, 'eval_accuracy': 0.8425, 'eval_runtime': 1.4562, 'eval_samples_per_second': 274.678, 'eval_steps_per_second': 9.614}\n",
      "Please see below to get compariosn details of results:\n",
      "First evaluation accuracy results: 0.5125\n",
      "Final evaluation accuray results: 0.8425\n"
     ]
    }
   ],
   "source": [
    "# This step is to load the fine-tuned model and to use trainer for evaluation\n",
    "f_tuned_model = AutoModelForSequenceClassification.from_pretrained(\"./peft_model\")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=f_tuned_model,\n",
    "    args=training_args,\n",
    "    eval_dataset=tokenized_val_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "Evaluation_result_f = trainer.evaluate()\n",
    "print(f\"Final evaluation result: {Evaluation_result_f}\")\n",
    "\n",
    "# This step is to show results\n",
    "print(f\"Please see below to get compariosn details of results:\")\n",
    "print(f\"First evaluation accuracy results: {Evaluation_result['eval_accuracy']}\")\n",
    "print(f\"Final evaluation accuray results: {Evaluation_result_f['eval_accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4261525f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
